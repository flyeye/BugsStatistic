Баги и статистика: введение
---------------------------

Это небольшое исследования посвящено решению проблемы оценки трудозатрат на исправление ошибок в ПО в процессе планирования очередного спринта. В отличии от разработки новой функциональности, оценить трудозатраты на исправления ошибки обычно на много сложнее или вообще невозможно. По сути, каждое такое исправление начинается с исследования, которое может занять в разы больше времени чем само исправление. Бывает так, что однозначно выявить причину ошибки вообще не получается, и тогда исправления производятся "наугад", как в медицине - так как анализы делать слишком долго и дорого начнем лечить от того, что можем. Если поможет - хорошо, если нет - значит это другая болезнь. А бывает так, что и с гипотезами проблемы и тогда сначала приходится расширять логи, писать какой-то вспомогательный код, который поможет что-то измерить, прояснить и т.д. Даже если поддержка приносит баг на блюдечке (с четким описанием как воспроизвести, с необходимым окружением), сказать заранее сколько времени уйдет на исправление невозможно.

Это порождает некоторую неопределенность при планировании. В какой-то момент времени мы решили, что таки баги будут рассматриваться как спайки и априори оцениваться в 4 идеальных часа. За это время разработчик должен разобраться с проблемой и либо исправить, либо предложить решение с новой оценкой. В итоге задача в любом случае переоценивается, либо в большую, либо в меньшую сторону.

Однако возникает ряд вопросов. Правильна ли выбрана оценка в 4 часа? Происходит ли компенсация на практике? Правильно ли вообще мы работаем с бажными тикетами, не ли здесь какой-то систематической проблемы?

Вторая группа вопросов касается свойств распределения случайной величины (то есть оценки трудозатрат на исправление бага) и происходит из моего спора с одним известным бизнес-тренером. Вкратце суть спора такова. Я задал вопрос: что он может порекомендовать (какие инструменты, методики) для планирования в том случае, когда априори трудозатраты на задачу не известны и по определению не могут быть оценены до начала работ. Ответ тренера был примерно таков: трудозатраты можно рассматривать как вероятностную величину (тут я согласен) распределенную нормально (а вот тут я не был согласен) и просто брать среднюю данного распределения. Простые задачи будут компенсировать сложные и все будет хорошо (тут я тоже не согласился, еще не имея конкретных цифр на руках, но помня, что происходит на спринтах). Поэтому вторая группа вопросов ставиться так: является ли распределение трудозатрат на исправление багов нормальным? Можно ли в данном случае использовать свойства нормального распределения (критерий 3 сигмы, оценку вероятности редких событий и т.д.)?

данные
------

были использованы данный по бажным тикетам, закрытым одной командой за период в 2.5 года в рамках одного большого проекта. Состав команды за это время сменился примерно на половину, но это происходило плавно. Костяк команды не менялся, в него входит 4 разработчика с опытом работы больше 15 лет (продуктовая команды, С++/С\#). Общая численность команды колебалась от 8 до 11 человек включая тестировщика и дизайнера/UX-специалиста.

После процедуры очистки получилась выборка из чуть более 900 тикетов. Вполне приличная выборка для статистического анализа. В выборку попали все баги, закрытые данной командой за последние 2.5 года. Это важно, иначе пришлось бы говорить об учете эффекта селекции.

Решение
-------

См. [полный текст исследования](https://github.com/flyeye/BugsStatistic/blob/master/bugs.html)

Ответы на вопросы
-----------------

Краткие ответы на вопросы, поставленные вначале будут такими:

1.  Исследуемое распределение не является нормальным;

2.  Вероятность поймать действительно сложный баг в жизни значительно больше, чем это предсказывает нормальное распределение;

3.  Однако в среднем на длительном интервале времени компенсация увеличения трудозатрат на сложные баги за счет экономии на простых происходит;

4.  Но только в рамках всей выборки, а в рамках рабочих спринтов ситуация хуже, на баланс рассчитывать не приходиться: примерно в трети спринтов гипотетический баланс существенно отрицателый;

5.  В жизни ситуацию еще более осложняет текущая методика априорной оценки, которая практически исключает эффект компенсации; средняя оценка недопланирования на спринте составляет ?16?±?14 часов;

6.  Черные лебеди конечно существуют, но как правило не попадают в статистику (аналог игровой ошибки по Талебу), так как в процессе "переваривания" раскладываются на множество тикетов, "размазанных" по нескольким спринтам, что искажает нашу оценку в лучшую сторону.

Попов Алексей, 15.08.2018
