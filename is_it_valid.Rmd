---
title: "Is it valid approach"
author: "Alexey Popov"
date: '13 января 2019 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(ggplot2)
require(moments)
require(normtest)
require(nortest)
require(stats)
        
require(tidyverse)
```

### А можно ли так делать? 

Внимательный читатель может возразить, мол вы работаете не с самой случаной величиной, а с усреднением случаной величины по неравномерным интервалам. Причем усредненной очень грубо, на глаз. Фактически, всем тикетам, попадающим в определенный интервал мы присваиваем фиксированную оцеку, ближайшее к среднему целое, но не среднее. Да, это так. По идее, усреднение не должно нам сильно мешаеть. А вот грубое усреднение помешать может. (тут надо бы вставить немножко теории, но сейчас на это нет времени). Давайте проведем следственный эксперимент (это и быстрее, и убедительнее). Смоделируем выборку (нормально распределенную, с заданным средним и дисперсией), усредним по неравномерным интервалам и посмотрим, останется ли наше распределение нормально распределенным. После этого повторим эксперимент, но уже не усредняя оценки, а назначая некую фиксированную оценку для каждого интервала как это происходит на практике. 

Сфорируем выборку сопоставимую по размерам с реальной, возьмем близкие среденее и дисперсию.
```{r}
z <- rnorm(1000, mean = 4, sd = 4)
mean(z)
sd(z)
```
Как проверить, является ли данное распределение нормальным? Для наглядности построим гистограмму, посчитаем асимметрию и эксцесс. 
```{r}
ggplot() + geom_histogram(aes(x = z), fill = "gray70", colour = "gray10") +
  scale_x_continuous(breaks=seq(-15,15,by=1)) +
  theme_bw()

skewness(z)
kurtosis(z)
```
Как можно видеть - все прекрасно. Асимметрия нулевая, эксцесс ~3.  

Проведем тестированием используя критерия согласия Хи-квадрат (критерий Пирсона). Используем готовый тест и дополнительно посчитаем критерий согласия вручную. 
```{r}
# теоретическая плотность вероятности
chi_c <- c(pnorm(0, mean = 4, sd = 4),
           pnorm(0.25, mean = 4, sd = 4) - pnorm(0, mean = 4, sd = 4),
           pnorm(0.75, mean = 4, sd = 4) - pnorm(0.25, mean = 4, sd = 4),
           pnorm(1.5, mean = 4, sd = 4) - pnorm(0.75, mean = 4, sd = 4),
           pnorm(3, mean = 4, sd = 4) - pnorm(1.5, mean = 4, sd = 4),
           pnorm(6, mean = 4, sd = 4) - pnorm(3, mean = 4, sd = 4),
           pnorm(12, mean = 4, sd = 4) - pnorm(6, mean = 4, sd = 4),
           pnorm(20, mean = 4, sd = 4) - pnorm(12, mean = 4, sd = 4),
           1 - pnorm(20, mean = 4, sd = 4))

# плотность распределения по модельным данным (не нормированная)
chi_o <- c(sum((z<=0)), 
             sum((z>0) & (z<=0.25)), 
             sum((z>0.25) & (z<=0.75)), 
             sum((z>0.75) & (z<=1.5)), 
             sum((z>1.5) & (z<=3)), 
             sum((z>3) & (z<=6)), 
             sum((z>6) & (z<=12)),
             sum((z>12) & (z<=20)), 
             sum((z>20)))

# встроенный тест
chisq.test(x = chi_o, p = chi_c)

# посчитаем Хи-квадрат вручную, критическое значение K = 18.54 для p = 0.05 и выбранного количества интервалов. 
sum(((chi_o[1:9] - chi_c[1:9]*length(z))^2)/(chi_c[1:9]*length(z)))

```
В соответствии с критерием Пирсона наше модельное распределение явсляется нормальным. Критерий Хи-квадрат вычисленный вручную и вычисленный в рамках теста равны. 


Проведем еще два популярных теста: Шапиро-Уилка и Харке-Бера (используеющих асиммметрию и эксцесс):
```{r}
jarque.test(z)
shapiro.test(z)
lillie.test(z)
```
Тесты уверенно говорят о том, что распределение нормальное. 

Теперь вместо реальных случайных значений подставим в нашу выборку ближайшее среднее по неравномерным интервалам. И снова проверим параметры выборки и проведем тесты. Понятно, что выбор интервалов усреденния тоже может играть роль, поэтому выберем интервалы, близкие к тем, что получаются на практике. 

```{r}
# сохраним исходную выборку
z0 <- z

# усредним по интервалам
z[(z<=0)] <- mean(z[(z<=0)]) 
z[(z>0) & (z<=0.25)] <- mean(z[(z>0) & (z<=0.25)]) 
z[(z>0.25) & (z<=0.75)] <- mean(z[(z>0.25) & (z<=0.75)]) 
z[(z>0.75) & (z<=1.5)] <- mean(z[(z>0.75) & (z<=1.5)]) 
z[(z>1.5) & (z<=3)] <- mean(z[(z>1.75) & (z<=3)])
z[(z>3) & (z<=6)] <- mean(z[(z>3) & (z<=6)])
z[(z>6) & (z<=12)] <- mean(z[(z>6) & (z<=12)])
z[(z>12) & (z<=20)] <- mean(z[(z>12) & (z<=20)]) 
z[(z>20)] <- mean(z[(z>20)])

mean(z)
sd(z)
```
Среднее не изменилось, слегка уменьшилась дисперсия.

Проверим выборку по критерию Хи-квадрат. 
```{r}
# плотность распределения по модельным данным (не нормированная)
chi_o <- c(sum((z<=0)),
             sum((z>0) & (z<=0.25)), 
             sum((z>0.25) & (z<=0.75)), 
             sum((z>0.75) & (z<=1.5)), 
             sum((z>1.5) & (z<=3)), 
             sum((z>3) & (z<=6)), 
             sum((z>6) & (z<=12)),
             sum((z>12) & (z<=20)), 
             sum((z>20)) )

# встроенный тест
chisq.test(x = chi_o, p = chi_c)

# посчитаем Хи-квадрат вручную, критическое значение K = 18.54 для p = 0.05 и выбранного количества интервалов. 
sum(((chi_o[1:9] - chi_c[1:9]*length(z))^2)/(chi_c[1:9]*length(z)))
```
Критерий Хи-квадрат меньше критической точки (K = 18.5). P-значение значительно больше 0.05. 

Проверим асимметрию и экцесс.
```{r}
skewness(z)
kurtosis(z)
```
Асимметрий близка к нулю, а эксцесс немного уменьшился. 


А что нам покажут тесты Харке-Бера, Шапиро-Уилка и Колмогорова-Смирнова?
```{r}
jarque.test(z)
shapiro.test(z)
lillie.test(z)
```
Тесты уже отказываются считать данное распределение нормальным. 


Для наглядности построим распределение.
```{r}
ggplot() + geom_histogram(aes(x = z), fill = "gray70", colour = "gray10") +
  scale_x_continuous(breaks=seq(-15,25,by=1)) +
  theme_bw()
```

Теперь повторим эксперимент, но уже использую фиксированную оценку для всех тикетов из заданного интервала.
```{r}
z <- z0
z[(z<=0)] <- mean(z[(z<=0)]) 
z[(z>0) & (z<=0.25)] <- 0.1 
z[(z>0.25) & (z<=0.75)] <- 0.5 
z[(z>0.75) & (z<=1.5)] <- 1
z[(z>1.5) & (z<=3)] <- 2 
z[(z>3) & (z<=6)] <- 4 
z[(z>6) & (z<=12)] <- 8
z[(z>12) & (z<=20)] <- 16 
z[(z>20)] <- 24 

#z <- z[z>0]

mean(z)
sd(z)

chi_o <- c(sum((z<=0)), 
             sum((z>0) & (z<=0.25)), 
             sum((z>0.25) & (z<=0.75)), 
             sum((z>0.75) & (z<=1.5)), 
             sum((z>1.5) & (z<=3)), 
             sum((z>3) & (z<=6)), 
             sum((z>6) & (z<=12)),
             sum((z>12) & (z<=20)), 
             sum((z>20)) )

# встроенный тест
chisq.test(x = chi_o, p = chi_c)

# посчитаем Хи-квадрат вручную, критическое значение K = 18.54 для p = 0.05 и выбранного количества интервалов. 
sum(((chi_o[1:9] - chi_c[1:9]*length(z))^2)/(chi_c[1:9]*length(z)))

skewness(z)


kurtosis(z)

jarque.test(z)
shapiro.test(z)
lillie.test(z)

ggplot() + geom_histogram(aes(x = z), fill = "gray70", colour = "gray10") +
  scale_x_continuous(breaks=seq(-15,25,by=1)) +
  theme_bw()
```
Среднее подрасло, среднеквадратическое отклонение слегка уменьшилось. Появилась небольшая асимметрия вправо, увеличился эксцесс. Проверка по критерию Хи-квадрат говорит, что распределение соответствует нормальну, но с очень небольшим запасом. Однако тесты Шапиро-Уилка и Харке-Бера уже видят большую разницу и не считают распределение нормальным. 


### Заключение

Таким образом, даже если исходная оценка трудозатрат распределена нормальна, наша метрика не является нормлаьно распределенной, так как усреднение (а тем более присвоение ближайшего целого к среднему) по интервалам ее "портит". 
