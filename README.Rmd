---
output:
  md_document:
    variant: markdown_github
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

## Баги и статистика: введение

Это небольшое исследования посвящено решению проблемы оценки трудозатрат на исправление ошибок в ПО в процессе планирования очередного спринта. В отличии от разработки новой функциональности, оценить трудозатраты на исправления ошибки обычно на много сложнее или вообще невозможно. По сути, каждое такое исправление начинается с исследования, которое может занять в разы больше времени чем само исправление. Бывает так, что однозначно выявить причину ошибки вообще не получается, и тогда исправления производятся "наугад", как в медицине - так как анализы делать слишком долго и дорого начнем лечить от того, что можем. Если поможет - хорошо, если нет - значит это другая болезнь. А бывает так, что и с гипотезами проблемы и тогда сначала приходится расширять логи, писать какой-то вспомогательный код, который поможет что-то измерить, прояснить и т.д. Даже если поддержка приносит баг на блюдечке (с четким описанием как воспроизвести, с необходимым окружением), сказать заранее сколько времени уйдет на исправление невозможно. 

Это порождает некоторую неопределенность при планировании. В какой-то момент времени мы решили, что таки баги будут рассматриваться как спайки и априори оцениваться в 4 идеальных часа. За это время разработчик должен разобраться с проблемой и либо исправить, либо предложить решение с новой оценкой. В итоге задача в любом случае переоценивается, либо в большую, либо в меньшую сторону. 

Однако возникает ряд вопросов. Правильна ли выбрана оценка в 4 часа? Происходит ли компенсация на практике? Правильно ли вообще мы работаем с бажными тикетами, не ли здесь какой-то систематической проблемы? 

Вторая группа вопросов касается свойств распределения случайной величины (то есть оценки трудозатрат на исправление бага) и происходит из моего спора с одним известным бизнес-тренером. Вкратце суть спора такова. Я задал вопрос: что он может порекомендовать (какие инструменты, методики) для планирования в том случае, когда априори трудозатраты на задачу не известны и по определению не могут быть оценены до начала работ. Ответ тренера был примерно таков: трудозатраты можно рассматривать как вероятностную величину (тут я согласен) распределенную нормально (а вот тут я не был согласен) и просто брать среднюю данного распределения. Простые задачи будут компенсировать сложные и все будет хорошо (тут я тоже не согласился, еще не имея конкретных цифр на руках, но помня, что происходит на спринтах). Поэтому вторая группа вопросов ставиться так: является ли распределение трудозатрат на исправление багов нормальным? Можно ли в данном случае использовать свойства нормального распределения (критерий 3 сигмы, оценку вероятности редких событий и т.д.)? 

## данные

были использованы данный по бажным тикетам, закрытым одной командой за период в 2.5 года в рамках одного большого проекта. Состав команды за это время сменился примерно на половину, но это происходило плавно. Костяк команды не менялся, в него входит 4 разработчика с опытом работы больше 15 лет (продуктовая команды, С++/С#). Общая численность команды колебалась от 8 до 11 человек включая тестировщика и дизайнера/UX-специалиста. 

После процедуры очистки получилась выборка из чуть более 900 тикетов. Вполне приличная выборка для статистического анализа. В выборку попали все баги, закрытые данной командой за последние 2.5 года. Это важно, иначе пришлось бы говорить об учете эффекта селекции. 

## Решение 

См. [полный текст исследования](https://github.com/flyeye/BugsStatistic/blob/master/bugs.html)

## Ответы на вопросы

Краткие ответы на вопросы, поставленные вначале будут такими: 

1. Исследуемое распределение не является нормальным;

2. Вероятность поймать действительно сложный баг в жизни значительно больше, чем это предсказывает нормальное распределение;

3. Однако в среднем на длительном интервале времени компенсация увеличения трудозатрат на сложные баги за счет экономии на простых происходит;

4. Но только в рамках всей выборки, а в рамках рабочих спринтов ситуация хуже, на баланс рассчитывать не приходиться: примерно в трети спринтов гипотетический баланс существенно отрицателый;

5. В жизни ситуацию еще более осложняет текущая методика априорной оценки, которая практически исключает эффект компенсации; средняя оценка недопланирования на спринте составляет $-16\pm 14$ часов;

6. Черные лебеди конечно существуют, но как правило не попадают в статистику (аналог игровой ошибки по Талебу), так как в процессе "переваривания" раскладываются на множество тикетов, "размазанных" по нескольким спринтам, что искажает нашу оценку в лучшую сторону. 
 
 
   Попов Алексей, 15.08.2018

